{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把字符串类型的数据转换为小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['benefits', 'company_profile', 'department', 'description',\n",
    "            'employment_type', 'function', 'industry', 'location', 'required_education',\n",
    "            'required_experience', 'requirements', 'title']:\n",
    "    train[col] = train[col].str.lower()\n",
    "    test[col] = test[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理缺失的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    if x == 'nan':\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split())\n",
    "\n",
    "\n",
    "for col in ['benefits', 'title', 'company_profile', 'description', 'requirements']:\n",
    "    train[f'{col}_wordsLen'] = train[col].astype('str').apply(lambda x: process(x))\n",
    "    test[f'{col}_wordsLen'] = test[col].astype('str').apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process1(x):\n",
    "    if x == 'nan':\n",
    "        return -999\n",
    "    else:\n",
    "        try:\n",
    "            return int(x.split('-')[0])\n",
    "        except:\n",
    "            return -998\n",
    "    \n",
    "def process2(x):\n",
    "    if x == 'nan':\n",
    "        return -999\n",
    "    else:\n",
    "        try:\n",
    "            return int(x.split('-')[1])\n",
    "        except:\n",
    "            return -998\n",
    "    \n",
    "\n",
    "train['salary_range_start'] = train['salary_range'].astype('str').apply(lambda x: process1(x))\n",
    "test['salary_range_start'] = test['salary_range'].astype('str').apply(lambda x: process1(x))\n",
    "\n",
    "train['salary_range_end'] = train['salary_range'].astype('str').apply(lambda x: process2(x))\n",
    "test['salary_range_end'] = test['salary_range'].astype('str').apply(lambda x: process2(x))\n",
    "\n",
    "del train['salary_range']\n",
    "del test['salary_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对具有明显分类的数据添加标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test])\n",
    "del train, test\n",
    "\n",
    "for f in tqdm(['department', 'employment_type', 'function', 'industry',\n",
    "               'location', 'required_education', 'required_experience', 'title']):\n",
    "    lbl = LabelEncoder()\n",
    "    df[f] = lbl.fit_transform(df[f].astype(str))\n",
    "\n",
    "train = df[df['fraudulent'].notnull()].copy()\n",
    "test = df[df['fraudulent'].isnull()].copy()\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过TF-IDF处理文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(train, test, colname, max_features):\n",
    "\n",
    "    text = list(train[colname].fillna('nan').values)\n",
    "    tf = TfidfVectorizer(min_df=0, \n",
    "                         ngram_range=(1,2), \n",
    "                         stop_words='english', \n",
    "                         max_features=max_features)\n",
    "    tf.fit(text)\n",
    "    X = tf.transform(text)\n",
    "    X_test = tf.transform(list(test[colname].fillna('nan').values))\n",
    "\n",
    "    df_tfidf = pd.DataFrame(X.todense())\n",
    "    df_tfidf_test = pd.DataFrame(X_test.todense())\n",
    "    df_tfidf.columns = [f'{colname}_tfidf{i}' for i in range(max_features)]\n",
    "    df_tfidf_test.columns = [f'{colname}_tfidf{i}' for i in range(max_features)]\n",
    "    for col in df_tfidf.columns:\n",
    "        train[col] = df_tfidf[col]\n",
    "        test[col] = df_tfidf_test[col]\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = get_tfidf(train, test, 'benefits', 12)\n",
    "train, test = get_tfidf(train, test, 'company_profile', 24)\n",
    "train, test = get_tfidf(train, test, 'description', 48)\n",
    "train, test = get_tfidf(train, test, 'requirements', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['benefits', 'company_profile', 'description', 'requirements']\n",
    "\n",
    "train = train.drop(to_drop, axis=1)\n",
    "test = test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'] = train.index\n",
    "test['id'] = test.index\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = 'fraudulent'\n",
    "feature_names = list(\n",
    "    filter(lambda x: x not in [ycol, 'id'], train.columns))\n",
    "\n",
    "model = lgb.LGBMClassifier(objective='binary',\n",
    "                           boosting_type='gbdt',\n",
    "                           tree_learner='serial',\n",
    "                           num_leaves=32,\n",
    "                           max_depth=6,\n",
    "                           learning_rate=0.1,\n",
    "                           n_estimators=10000,\n",
    "                           subsample=0.8,\n",
    "                           feature_fraction=0.6,\n",
    "                           reg_alpha=10,\n",
    "                           reg_lambda=12,\n",
    "                           random_state=1983,\n",
    "                           is_unbalance=True,\n",
    "                           metric='auc')\n",
    "\n",
    "\n",
    "oof = []\n",
    "prediction = test[['id']]\n",
    "prediction['fraudulent'] = 0\n",
    "df_importance_list = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1983)\n",
    "for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(train[feature_names], train[ycol])):\n",
    "    X_train = train.iloc[trn_idx][feature_names]\n",
    "    Y_train = train.iloc[trn_idx][ycol]\n",
    "\n",
    "    X_val = train.iloc[val_idx][feature_names]\n",
    "    Y_val = train.iloc[val_idx][ycol]\n",
    "\n",
    "    print('\\nFold_{} Training ================================\\n'.format(fold_id+1))\n",
    "\n",
    "    lgb_model = model.fit(X_train,\n",
    "                          Y_train,\n",
    "                          eval_names=['train', 'valid'],\n",
    "                          eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "                          verbose=500,\n",
    "                          eval_metric='auc',\n",
    "                          early_stopping_rounds=50)\n",
    "\n",
    "    pred_val = lgb_model.predict(\n",
    "        X_val, num_iteration=lgb_model.best_iteration_)\n",
    "    df_oof = train.iloc[val_idx][['id', ycol]].copy()\n",
    "    df_oof['pred'] = pred_val\n",
    "    oof.append(df_oof)\n",
    "\n",
    "    pred_test = lgb_model.predict(\n",
    "        test[feature_names], num_iteration=lgb_model.best_iteration_)\n",
    "    prediction['fraudulent'] += pred_test / kfold.n_splits\n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "        'column': feature_names,\n",
    "        'importance': lgb_model.feature_importances_,\n",
    "    })\n",
    "    df_importance_list.append(df_importance)\n",
    "\n",
    "    del lgb_model, pred_val, pred_test, X_train, Y_train, X_val, Y_val\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看元素数据各个元素的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_importance = pd.concat(df_importance_list)\n",
    "df_importance = df_importance.groupby(['column'])['importance'].agg(\n",
    "    'mean').sort_values(ascending=False).reset_index()\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得lgb模型训练后的得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(oof)\n",
    "\n",
    "score = accuracy_score(df_oof[ycol].astype('int'), df_oof['pred'].astype('int'))\n",
    "print('auc:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction.fraudulent.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对预测结果进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = prediction.copy(deep=True)\n",
    "sub['fraudulent'] = sub['fraudulent'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "print(sub.fraudulent.value_counts())\n",
    "\n",
    "sub.to_csv('submissions.csv'.format(score), index=False, header=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
